{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle European Soccer Database Analysis\n",
    "### Extract Ball Event Data from Match Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are downloaded here: [Kaggle European Soccer Database](https://www.kaggle.com/hugomathien/soccer).\n",
    "\n",
    "This notebook is to extract ball-event data from match table. The ball events are stored in match table with xml style, so it has to be extracted for further data analysis.\n",
    "\n",
    "### Table of Contents\n",
    "#### 1. [Extract Goal Event](#1)\n",
    "#### 2. [Extract Shoton Event](#2)\n",
    "#### 3. [Extract Shotoff Event](#3)\n",
    "#### 4. [Extract Foulcommit Event](#4)\n",
    "#### 5. [Extract Card Event](#5)\n",
    "#### 6. [Extract Cross Event](#6)\n",
    "#### 7. [Extract Corner Event](#7)\n",
    "#### 8. [Extract Possession Event](#8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All general modules are imported.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import bs4\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "print('All general modules are imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to the database is established.\n",
      "\n",
      "Following Tables are found in the database:\n",
      "sqlite_sequence\n",
      "Player_Attributes\n",
      "Player\n",
      "Match\n",
      "League\n",
      "Country\n",
      "Team\n",
      "Team_Attributes\n"
     ]
    }
   ],
   "source": [
    "# Establish connection to sql database\n",
    "\n",
    "# database file name\n",
    "db_filename = 'database.sqlite'\n",
    "\n",
    "# change database file directory as you wish\n",
    "db_filedir = os.path.join(os.path.pardir, os.path.pardir, os.path.pardir, 'data_source', 'kaggle', db_filename)\n",
    "\n",
    "try:\n",
    "    con=sqlite3.connect(db_filedir)\n",
    "    print('Connection to the database is established.\\n')\n",
    "except Exception as e:\n",
    "    print('Unable to establish the connection.')\n",
    "\n",
    "cursor=con.execute(\"select name from sqlite_master where type='table'\")\n",
    "print('Following Tables are found in the database:')\n",
    "for i in cursor.fetchall():\n",
    "    print('{}'.format(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load match table from the database.\n"
     ]
    }
   ],
   "source": [
    "# read match table\n",
    "try:\n",
    "    match = pd.read_sql_query('select * from Match',con)\n",
    "    print('Successfully load match table from the database.')\n",
    "except Exception as e:\n",
    "    print('Unable to load match table from the database.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the folder directory as you wish to store the exported data files\n",
    "export_folder = os.path.join(os.path.pardir, os.path.pardir, os.path.pardir, 'data_source', 'kaggle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='1'></a>1. Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this on if you want to parse goal information\n",
    "parse_goal = False\n",
    "\n",
    "if parse_goal:\n",
    "    #Create empty lists to store extracted data\n",
    "    id_list=[]\n",
    "    type_list=[]\n",
    "    subtype_list=[]\n",
    "    goal_type_list=[]\n",
    "    player1_list=[]\n",
    "    player2_list=[]\n",
    "    team_list=[]\n",
    "    elapsed_list=[]\n",
    "    longitude_list=[]\n",
    "    latitude_list=[]\n",
    "    match_id_list=[]\n",
    "    elapsed_plus_list=[]\n",
    "    \n",
    "    # Loop over all available rows\n",
    "    for i in tqdm(np.arange(match[match['goal'].notnull()].shape[0]), desc='Extracting Goal Events', unit='matches'):\n",
    "        \n",
    "        # Create a soup to parse\n",
    "        soup = bs4.BeautifulSoup(match[match['goal'].notnull()].iloc[i]['goal'],'lxml')\n",
    "        \n",
    "        # Loop over all events\n",
    "        for element in soup.goal.find_all('value',recursive=False):\n",
    "            \n",
    "            # Get id\n",
    "            try:\n",
    "                id_list.append(element.find('id').text)\n",
    "            except AttributeError:\n",
    "                id_list.append(np.nan)\n",
    "            \n",
    "            # Get event type    \n",
    "            try:\n",
    "                type_list.append(element.find('type').text)\n",
    "            except AttributeError:\n",
    "                type_list.append(np.nan)\n",
    "            \n",
    "            # Get event subtype\n",
    "            try:\n",
    "                subtype_list.append(element.find('subtype').text)\n",
    "            except AttributeError:\n",
    "                subtype_list.append(np.nan)\n",
    "            \n",
    "            # Get goal type\n",
    "            try:\n",
    "                goal_type_list.append(element.find('goal_type').text)\n",
    "            except AttributeError:\n",
    "                goal_type_list.append(np.nan)\n",
    "            \n",
    "            # Get player 1\n",
    "            try:\n",
    "                player1_list.append(element.find('player1').text)\n",
    "            except AttributeError:\n",
    "                player1_list.append(np.nan)\n",
    "            \n",
    "            # Get player 2    \n",
    "            try:\n",
    "                player2_list.append(element.find('player2').text)\n",
    "            except AttributeError:\n",
    "                player2_list.append(np.nan)\n",
    "            \n",
    "            # Get team\n",
    "            try:\n",
    "                team_list.append(element.find('team').text)\n",
    "            except AttributeError:\n",
    "                team_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed time\n",
    "            try:\n",
    "                elapsed_list.append(element.find('elapsed').text)\n",
    "            except AttributeError:\n",
    "                elapsed_list.append(element.find(np.nan))\n",
    "            \n",
    "            # Get elapsed plus_time\n",
    "            try:\n",
    "                elapsed_plus_list.append(element.find('elapsed_plus').text)\n",
    "            except AttributeError:\n",
    "                elapsed_plus_list.append(element.find(np.nan)) \n",
    "            \n",
    "            # Get longitude\n",
    "            try:\n",
    "                longitude_list.append(element.find_all('value')[0].text)\n",
    "            except IndexError:\n",
    "                longitude_list.append(np.nan)\n",
    "            \n",
    "            # Get latitude\n",
    "            try:\n",
    "                latitude_list.append(element.find_all('value')[1].text)\n",
    "            except IndexError:\n",
    "                latitude_list.append(np.nan)\n",
    "            \n",
    "            # Get match id    \n",
    "            match_id_list.append(match[match['goal'].notnull()].iloc[i]['match_api_id'])\n",
    "    \n",
    "    # Create a dictionary\n",
    "    goal_dic = {'id': id_list,\n",
    "                'type': type_list,\n",
    "                'subtype': subtype_list,\n",
    "                'goal_type': goal_type_list,\n",
    "                'player1': player1_list,\n",
    "                'player2': player2_list,\n",
    "                'team': team_list,\n",
    "                'elapsed': elapsed_list,\n",
    "                'longitude':longitude_list,\n",
    "                'latitude':latitude_list,\n",
    "                'match_api_id':match_id_list,\n",
    "                'elapsed_plus':elapsed_plus_list}\n",
    "    \n",
    "    # Create a dataframe\n",
    "    goal = pd.DataFrame(goal_dic)\n",
    "    \n",
    "    # Change data types to be consistent with database\n",
    "    goal.elapsed = pd.to_numeric(goal.elapsed, errors='coerce')\n",
    "    goal.elapsed_plus = pd.to_numeric(goal.elapsed_plus, errors='coerce')\n",
    "    goal.id = pd.to_numeric(goal.id, errors='coerce')\n",
    "    goal.latitude = pd.to_numeric(goal.latitude, errors='coerce')\n",
    "    goal.longitude = pd.to_numeric(goal.longitude, errors='coerce')\n",
    "    goal.match_api_id = pd.to_numeric(goal.match_api_id, errors='coerce')\n",
    "    goal.player1 = pd.to_numeric(goal.player1, errors='coerce')\n",
    "    goal.player2 = pd.to_numeric(goal.player2, errors='coerce')\n",
    "    goal.team = pd.to_numeric(goal.team, errors='coerce')\n",
    "    \n",
    "    # Save to local disk\n",
    "    # If data file has not been generated in the same folder yet\n",
    "    if not os.path.isfile(os.path.join(export_folder, 'goal.data')):\n",
    "        print('Saving goal dataset to file...')\n",
    "        try:\n",
    "            with open(os.path.join(export_folder, 'goal.data'), 'wb') as f:\n",
    "                pickle.dump(goal, f)\n",
    "            print('Goal dataset has been saved to goal.data')\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to: goal.data')\n",
    "    else:\n",
    "        print('goal dataset is cached in file: goal.data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='2'></a>2. Shoton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this on if you want to parse shoton information\n",
    "parse_shoton = False\n",
    "\n",
    "if parse_shoton:\n",
    "    #Create empty lists to store extracted data\n",
    "    id_list=[]\n",
    "    type_list=[]\n",
    "    subtype_list=[]\n",
    "    player1_list=[]\n",
    "    team_list=[]\n",
    "    elapsed_list=[]\n",
    "    elapsed_plus_list=[]\n",
    "    longitude_list=[]\n",
    "    latitude_list=[]\n",
    "    match_id_list=[]\n",
    "    \n",
    "    # Loop over all available rows\n",
    "    for i in tqdm(np.arange(match[match['shoton'].notnull()].shape[0]), desc='Extracting Shoton Events', unit='matches'):\n",
    "        \n",
    "        # Create a soup to parse\n",
    "        soup = bs4.BeautifulSoup(match[match['shoton'].notnull()].iloc[i]['shoton'],'lxml')\n",
    "        \n",
    "        # Loop over all events\n",
    "        for element in soup.shoton.find_all('value',recursive=False):\n",
    "            # Get id\n",
    "            try:\n",
    "                id_list.append(element.find('id').text)\n",
    "            except AttributeError:\n",
    "                id_list.append(np.nan)\n",
    "            \n",
    "            # Get event type\n",
    "            try:\n",
    "                type_list.append(element.find('type').text)\n",
    "            except AttributeError:\n",
    "                type_list.append(np.nan)\n",
    "                \n",
    "            # Get event subtype\n",
    "            try:\n",
    "                subtype_list.append(element.find('subtype').text)\n",
    "            except AttributeError:\n",
    "                subtype_list.append(np.nan)\n",
    "            \n",
    "            # Get player 1\n",
    "            try:\n",
    "                player1_list.append(element.find('player1').text)\n",
    "            except AttributeError:\n",
    "                player1_list.append(np.nan)\n",
    "            \n",
    "            # Get team\n",
    "            try:\n",
    "                team_list.append(element.find('team').text)\n",
    "            except AttributeError:\n",
    "                team_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed time\n",
    "            try:\n",
    "                elapsed_list.append(element.find('elapsed').text)\n",
    "            except AttributeError:\n",
    "                elapsed_list.append(element.find(np.nan))\n",
    "            \n",
    "            # Get elapsed plus_time\n",
    "            try:\n",
    "                elapsed_plus_list.append(element.find('elapsed_plus').text)\n",
    "            except AttributeError:\n",
    "                elapsed_plus_list.append(element.find(np.nan))\n",
    "            \n",
    "            # Get longitude\n",
    "            try:\n",
    "                longitude_list.append(element.find_all('value')[0].text)\n",
    "            except IndexError:\n",
    "                longitude_list.append(np.nan)\n",
    "            \n",
    "            # Get latitude\n",
    "            try:\n",
    "                latitude_list.append(element.find_all('value')[1].text)\n",
    "            except IndexError:\n",
    "                latitude_list.append(np.nan)\n",
    "            \n",
    "            # Get match id\n",
    "            match_id_list.append(match[match['shoton'].notnull()].iloc[i]['match_api_id'])\n",
    "    \n",
    "    # Create a dictionary        \n",
    "    shoton_dic = {'id': id_list,\n",
    "                  'type': type_list,\n",
    "                  'subtype': subtype_list,\n",
    "                  'player1': player1_list,\n",
    "                  'team': team_list,\n",
    "                  'elapsed': elapsed_list,\n",
    "                  'elapsed_plus':elapsed_plus_list,\n",
    "                  'longitude':longitude_list,\n",
    "                  'latitude':latitude_list,\n",
    "                  'match_api_id':match_id_list}\n",
    "    \n",
    "    # Create a dataframe\n",
    "    shoton = pd.DataFrame(shoton_dic)\n",
    "    \n",
    "    # Change data types to be consistent with database\n",
    "    shoton.elapsed = pd.to_numeric(shoton.elapsed, errors='coerce')\n",
    "    shoton.elapsed_plus = pd.to_numeric(shoton.elapsed_plus, errors='coerce')\n",
    "    shoton.id = pd.to_numeric(shoton.id, errors='coerce')\n",
    "    shoton.latitude = pd.to_numeric(shoton.latitude, errors='coerce')\n",
    "    shoton.longitude = pd.to_numeric(shoton.longitude, errors='coerce')\n",
    "    shoton.player1 = pd.to_numeric(shoton.player1, errors='coerce')\n",
    "    shoton.team = pd.to_numeric(shoton.team, errors='coerce')\n",
    "    \n",
    "    # Save to local disk\n",
    "    # If data file has not been generated in the same folder yet\n",
    "    if not os.path.isfile(os.path.join(export_folder, 'shoton.data')):\n",
    "        print('Saving shoton dataset to file...')\n",
    "        try:\n",
    "            with open(os.path.join(export_folder, 'shoton.data'), 'wb') as f:\n",
    "                pickle.dump(shoton, f)\n",
    "            print('shoton dataset has been saved to shoton.data')\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to: shoton.data')\n",
    "    else:\n",
    "        print('shoton dataset is cached in file: shoton.data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='3'></a>3. Shotoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this on if you want to shotoff goal information\n",
    "parse_shotoff = False\n",
    "\n",
    "if parse_shotoff:\n",
    "    #Create empty lists to store extracted data\n",
    "    id_list=[]\n",
    "    type_list=[]\n",
    "    subtype_list=[]\n",
    "    player1_list=[]\n",
    "    team_list=[]\n",
    "    elapsed_list=[]\n",
    "    match_id_list=[]\n",
    "    elapsed_plus_list=[]\n",
    "    longitude_list=[]\n",
    "    latitude_list=[]\n",
    "    \n",
    "    # Loop over all available rows\n",
    "    for i in tqdm(np.arange(match[match['shotoff'].notnull()].shape[0]), desc='Extracting Shotoff Events', unit='matches'):\n",
    "        \n",
    "        # Create a soup to parse\n",
    "        soup = bs4.BeautifulSoup(match[match['shotoff'].notnull()].iloc[i]['shotoff'],'lxml')\n",
    "        \n",
    "        # Loop over all events\n",
    "        for element in soup.shotoff.find_all('value',recursive=False):\n",
    "            \n",
    "            # Get event id\n",
    "            try:\n",
    "                id_list.append(element.find('id').text)\n",
    "            except AttributeError:\n",
    "                id_list.append(np.nan)\n",
    "            \n",
    "            # Get event type\n",
    "            try:\n",
    "                type_list.append(element.find('type').text)\n",
    "            except AttributeError:\n",
    "                type_list.append(np.nan)\n",
    "            \n",
    "            # Get event subtype\n",
    "            try:\n",
    "                subtype_list.append(element.find('subtype').text)\n",
    "            except AttributeError:\n",
    "                subtype_list.append(np.nan)\n",
    "            \n",
    "            # Get player1\n",
    "            try:\n",
    "                player1_list.append(element.find('player1').text)\n",
    "            except AttributeError:\n",
    "                player1_list.append(np.nan)\n",
    "            \n",
    "            # Get team\n",
    "            try:\n",
    "                team_list.append(element.find('team').text)\n",
    "            except AttributeError:\n",
    "                team_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed time\n",
    "            try:\n",
    "                elapsed_list.append(element.find('elapsed').text)\n",
    "            except AttributeError:\n",
    "                elapsed_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed plus_time\n",
    "            try:\n",
    "                elapsed_plus_list.append(element.find('elapsed_plus').text)\n",
    "            except AttributeError:\n",
    "                elapsed_plus_list.append(np.nan)\n",
    "            \n",
    "            # Get longitude\n",
    "            try:\n",
    "                longitude_list.append(element.find_all('value')[0].text)\n",
    "            except IndexError:\n",
    "                longitude_list.append(np.nan)\n",
    "            \n",
    "            # Get latitude\n",
    "            try:\n",
    "                latitude_list.append(element.find_all('value')[1].text)\n",
    "            except IndexError:\n",
    "                latitude_list.append(np.nan)\n",
    "            \n",
    "            # Get match id\n",
    "            match_id_list.append(match[match['shotoff'].notnull()].iloc[i]['match_api_id'])\n",
    "    \n",
    "    # Create a dictionary\n",
    "    shotoff_dic = {'id': id_list,\n",
    "                   'type': type_list,              \n",
    "                   'subtype': subtype_list,              \n",
    "                   'player1': player1_list,              \n",
    "                   'team': team_list,\n",
    "                   'elapsed': elapsed_list,\n",
    "                   'elapsed_plus':elapsed_plus_list,\n",
    "                   'match_api_id':match_id_list,\n",
    "                   'longitude':longitude_list,\n",
    "                   'latitude':latitude_list}\n",
    "    \n",
    "    # Create a dataframe\n",
    "    shotoff = pd.DataFrame(shotoff_dic)\n",
    "    \n",
    "    # Change data types to be consistent with database\n",
    "    shotoff.elapsed = pd.to_numeric(shotoff.elapsed, errors='coerce')\n",
    "    shotoff.elapsed_plus = pd.to_numeric(shotoff.elapsed_plus, errors='coerce')\n",
    "    shotoff.id = pd.to_numeric(shotoff.id, errors='coerce')\n",
    "    shotoff.latitude = pd.to_numeric(shotoff.latitude, errors='coerce')\n",
    "    shotoff.longitude = pd.to_numeric(shotoff.longitude, errors='coerce')\n",
    "    shotoff.player1 = pd.to_numeric(shotoff.player1, errors='coerce')\n",
    "    shotoff.team = pd.to_numeric(shotoff.team, errors='coerce')\n",
    "    \n",
    "    # Save to local disk\n",
    "    # If data file has not been generated in the same folder yet\n",
    "    if not os.path.isfile(os.path.join(export_folder, 'shotoff.data')):\n",
    "        print('Saving shotoff dataset to file...')\n",
    "        try:\n",
    "            with open(os.path.join(export_folder, 'shotoff.data'), 'wb') as f:\n",
    "                pickle.dump(shotoff, f)\n",
    "            print('shotoff dataset has been saved to shotoff.data')\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to: shotoff.data')\n",
    "    else:\n",
    "        print('shotoff dataset is cached in file: shotoff.data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='4'></a>4. Foulcommit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this on if you want to parse foulcommit information\n",
    "parse_foulcommit = False\n",
    "\n",
    "if parse_foulcommit:\n",
    "    #Create empty lists to store extracted data\n",
    "    id_list=[]\n",
    "    type_list=[]\n",
    "    player1_list=[]\n",
    "    player2_list=[]\n",
    "    team_list=[]\n",
    "    elapsed_list=[]\n",
    "    match_id_list=[]\n",
    "    elapsed_plus_list=[]\n",
    "    subtype_list=[]\n",
    "    \n",
    "    # Loop over all available rows\n",
    "    for i in tqdm(np.arange(match[match['foulcommit'].notnull()].shape[0]), desc='Extracting Foulcommit Events', unit='matches'):\n",
    "        \n",
    "        # Create a soup to parse\n",
    "        soup = bs4.BeautifulSoup(match[match['foulcommit'].notnull()].iloc[i]['foulcommit'],'lxml')\n",
    "        \n",
    "        # Loop over all events\n",
    "        for element in soup.foulcommit.find_all('value',recursive=False):\n",
    "            \n",
    "            # Get event id\n",
    "            try:\n",
    "                id_list.append(element.find('id').text)\n",
    "            except AttributeError:\n",
    "                id_list.append(np.nan)\n",
    "            \n",
    "            # Get event type\n",
    "            try:\n",
    "                type_list.append(element.find('type').text)\n",
    "            except AttributeError:\n",
    "                type_list.append(np.nan)        \n",
    "            \n",
    "            # Get player2\n",
    "            try:\n",
    "                player2_list.append(element.find('player2').text)\n",
    "            except AttributeError:\n",
    "                player2_list.append(np.nan)\n",
    "            \n",
    "            # Get player1\n",
    "            try:\n",
    "                player1_list.append(element.find('player1').text)\n",
    "            except AttributeError:\n",
    "                player1_list.append(np.nan)\n",
    "            \n",
    "            # Get team\n",
    "            try:\n",
    "                team_list.append(element.find('team').text)\n",
    "            except AttributeError:\n",
    "                team_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed time\n",
    "            try:\n",
    "                elapsed_list.append(element.find('elapsed').text)\n",
    "            except AttributeError:\n",
    "                elapsed_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed plus_time\n",
    "            try:\n",
    "                elapsed_plus_list.append(element.find('elapsed_plus').text)\n",
    "            except AttributeError:\n",
    "                elapsed_plus_list.append(np.nan)\n",
    "            \n",
    "            # Get event subtype\n",
    "            try:\n",
    "                subtype_list.append(element.find('subtype').text)\n",
    "            except AttributeError:\n",
    "                subtype_list.append(np.nan)\n",
    "            \n",
    "            # Get match id\n",
    "            match_id_list.append(match[match['foulcommit'].notnull()].iloc[i]['match_api_id'])\n",
    "    \n",
    "    # Create a dictionary\n",
    "    foulcommit_dic = {'id': id_list,                \n",
    "                      'type': type_list,         \n",
    "                      'player1': player1_list,\n",
    "                      'player2': player2_list,                \n",
    "                      'team': team_list,\n",
    "                      'elapsed': elapsed_list,          \n",
    "                      'elapsed_plus':elapsed_plus_list,\n",
    "                      'subtype': subtype_list,\n",
    "                      'match_api_id':match_id_list}\n",
    "    \n",
    "    # Create a dataframe\n",
    "    foulcommit = pd.DataFrame(foulcommit_dic)\n",
    "    \n",
    "    # Change data types to be consistent with database\n",
    "    foulcommit.elapsed = pd.to_numeric(foulcommit.elapsed, errors='coerce')\n",
    "    foulcommit.elapsed_plus = pd.to_numeric(foulcommit.elapsed_plus, errors='coerce')\n",
    "    foulcommit.id = pd.to_numeric(foulcommit.id, errors='coerce')\n",
    "    foulcommit.player1 = pd.to_numeric(foulcommit.player1, errors='coerce')\n",
    "    foulcommit.player2 = pd.to_numeric(foulcommit.player2, errors='coerce')\n",
    "    foulcommit.team = pd.to_numeric(foulcommit.team, errors='coerce')\n",
    "    \n",
    "    # Save to local disk\n",
    "    # If data file has not been generated in the same folder yet\n",
    "    if not os.path.isfile(os.path.join(export_folder, 'foulcommit.data')):\n",
    "        print('Saving foulcommit dataset to file...')\n",
    "        try:\n",
    "            with open(os.path.join(export_folder, 'foulcommit.data'), 'wb') as f:\n",
    "                pickle.dump(foulcommit, f)\n",
    "            print('foulcommit dataset has been saved to foulcommit.data')\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to: foulcommit.data')\n",
    "    else:\n",
    "        print('foulcommit dataset is cached in file: foulcommit.data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='5'></a>5. Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this on if you want to parse card information\n",
    "parse_card = False\n",
    "\n",
    "if parse_card:\n",
    "    #Create empty lists to store extracted data\n",
    "    id_list=[]\n",
    "    type_list=[]\n",
    "    subtype_list=[]\n",
    "    player1_list=[]\n",
    "    team_list=[]\n",
    "    elapsed_list=[]\n",
    "    match_id_list=[]\n",
    "    elapsed_plus_list=[]\n",
    "    card_type_list=[]\n",
    "    \n",
    "    # Loop over all available rows\n",
    "    for i in tqdm(np.arange(match[match['card'].notnull()].shape[0]), desc='Extracting Card Events', unit='matches'):\n",
    "        \n",
    "        # Create a soup to parse\n",
    "        soup = bs4.BeautifulSoup(match[match['card'].notnull()].iloc[i]['card'],'lxml')\n",
    "        \n",
    "        # Loop over all events\n",
    "        for element in soup.card.find_all('value',recursive=False):\n",
    "            \n",
    "            # Get event id\n",
    "            try:\n",
    "                id_list.append(element.find('id').text)\n",
    "            except AttributeError:\n",
    "                id_list.append(np.nan)\n",
    "            \n",
    "            # Get event type\n",
    "            try:\n",
    "                type_list.append(element.find('type').text)\n",
    "            except AttributeError:\n",
    "                type_list.append(np.nan)\n",
    "            \n",
    "            # Get event subtype\n",
    "            try:\n",
    "                subtype_list.append(element.find('subtype').text)\n",
    "            except AttributeError:\n",
    "                subtype_list.append(np.nan)\n",
    "            \n",
    "            # Get card type\n",
    "            try:\n",
    "                card_type_list.append(element.find('card_type').text)\n",
    "            except AttributeError:\n",
    "                card_type_list.append(np.nan)\n",
    "            \n",
    "            # Get player1\n",
    "            try:\n",
    "                player1_list.append(element.find('player1').text)\n",
    "            except AttributeError:\n",
    "                player1_list.append(np.nan)\n",
    "            \n",
    "            # Get team\n",
    "            try:\n",
    "                team_list.append(element.find('team').text)\n",
    "            except AttributeError:\n",
    "                team_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed time\n",
    "            try:\n",
    "                elapsed_list.append(element.find('elapsed').text)\n",
    "            except AttributeError:\n",
    "                elapsed_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed plus_time\n",
    "            try:\n",
    "                elapsed_plus_list.append(element.find('elapsed_plus').text)\n",
    "            except AttributeError:\n",
    "                elapsed_plus_list.append(np.nan)\n",
    "            \n",
    "            # Get match id\n",
    "            match_id_list.append(match[match['card'].notnull()].iloc[i]['match_api_id'])\n",
    "    \n",
    "    # Create a dictionary\n",
    "    card_dic = {'id': id_list,\n",
    "                'type': type_list,\n",
    "                'subtype':subtype_list,\n",
    "                'cardtype':card_type_list,\n",
    "                'player1': player1_list,                                 \n",
    "                'team': team_list,                  \n",
    "                'elapsed': elapsed_list,                           \n",
    "                'elapsed_plus':elapsed_plus_list,                               \n",
    "                'match_api_id':match_id_list}\n",
    "    \n",
    "    # Create a dataframe\n",
    "    card = pd.DataFrame(card_dic)\n",
    "    \n",
    "    # Change data types to be consistent with database\n",
    "    card.elapsed = pd.to_numeric(card.elapsed, errors='coerce')\n",
    "    card.elapsed_plus = pd.to_numeric(card.elapsed_plus, errors='coerce')\n",
    "    card.id = pd.to_numeric(card.id, errors='coerce')\n",
    "    card.player1 = pd.to_numeric(card.player1, errors='coerce')\n",
    "    card.team = pd.to_numeric(card.team, errors='coerce')\n",
    "    \n",
    "    # Save to local disk\n",
    "    # If data file has not been generated in the same folder yet\n",
    "    if not os.path.isfile(os.path.join(export_folder, 'card.data')):\n",
    "        print('Saving card dataset to file...')\n",
    "        try:\n",
    "            with open(os.path.join(export_folder, 'card.data'), 'wb') as f:\n",
    "                pickle.dump(card, f)\n",
    "            print('card dataset has been saved to card.data')\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to: card.data')\n",
    "    else:\n",
    "        print('card dataset is cached in file: card.data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='6'></a>6. Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this on if you want to parse cross information\n",
    "parse_cross = False\n",
    "\n",
    "if parse_cross:\n",
    "    #Create empty lists to store extracted data\n",
    "    id_list=[]\n",
    "    type_list=[]\n",
    "    subtype_list=[]\n",
    "    player1_list=[]\n",
    "    team_list=[]\n",
    "    elapsed_list=[]\n",
    "    match_id_list=[]\n",
    "    elapsed_plus_list=[]\n",
    "    \n",
    "    # Loop over all available rows\n",
    "    for i in tqdm(np.arange(match[match['cross'].notnull()].shape[0]), desc='Extracting Cross Events', unit='matches'):\n",
    "        \n",
    "        # Create a soup to parse\n",
    "        soup = bs4.BeautifulSoup(match[match['cross'].notnull()].iloc[i]['cross'],'lxml')\n",
    "        \n",
    "        # Loop over all events\n",
    "        for element in soup.cross.find_all('value',recursive=False):\n",
    "            \n",
    "            # Get event id\n",
    "            try:\n",
    "                id_list.append(element.find('id').text)\n",
    "            except AttributeError:\n",
    "                id_list.append(np.nan)\n",
    "            \n",
    "            # Get event type\n",
    "            try:\n",
    "                type_list.append(element.find('type').text)\n",
    "            except AttributeError:\n",
    "                type_list.append(np.nan)\n",
    "            \n",
    "            # Get event subtype\n",
    "            try:\n",
    "                subtype_list.append(element.find('subtype').text)\n",
    "            except AttributeError:\n",
    "                subtype_list.append(np.nan)\n",
    "            \n",
    "            # Get player1\n",
    "            try:\n",
    "                player1_list.append(element.find('player1').text)\n",
    "            except AttributeError:\n",
    "                player1_list.append(np.nan)\n",
    "            \n",
    "            # Get team\n",
    "            try:\n",
    "                team_list.append(element.find('team').text)\n",
    "            except AttributeError:\n",
    "                team_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed time\n",
    "            try:\n",
    "                elapsed_list.append(element.find('elapsed').text)\n",
    "            except AttributeError:\n",
    "                elapsed_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed plus_time\n",
    "            try:\n",
    "                elapsed_plus_list.append(element.find('elapsed_plus').text)\n",
    "            except AttributeError:\n",
    "                elapsed_plus_list.append(np.nan)\n",
    "            \n",
    "            # Get match id\n",
    "            match_id_list.append(match[match['cross'].notnull()].iloc[i]['match_api_id'])\n",
    "    \n",
    "    # Create a dictionary\n",
    "    cross_dic = {'id': id_list,            \n",
    "                 'type': type_list,            \n",
    "                 'subtype':subtype_list,            \n",
    "                 'player1': player1_list,\n",
    "                 'team': team_list,                \n",
    "                 'elapsed_plus':elapsed_plus_list,\n",
    "                 'match_api_id':match_id_list}\n",
    "    \n",
    "    # Create a dataframe\n",
    "    cross = pd.DataFrame(cross_dic)\n",
    "    \n",
    "    # Change data types to be consistent with database\n",
    "    cross.elapsed = pd.to_numeric(cross.elapsed, errors='coerce')\n",
    "    cross.elapsed_plus = pd.to_numeric(cross.elapsed_plus, errors='coerce')\n",
    "    cross.id = pd.to_numeric(cross.id, errors='coerce')\n",
    "    cross.player1 = pd.to_numeric(cross.player1, errors='coerce')\n",
    "    cross.team = pd.to_numeric(cross.team, errors='coerce')\n",
    "    \n",
    "    # If data file has not been generated in the same folder yet\n",
    "    if not os.path.isfile(os.path.join(export_folder, 'cross.data')):\n",
    "        print('Saving cross dataset to file...')\n",
    "        try:\n",
    "            with open(os.path.join(export_folder, 'cross.data'), 'wb') as f:\n",
    "                pickle.dump(cross, f)\n",
    "            print('cross dataset has been saved to cross.data')\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to: cross.data')\n",
    "    else:\n",
    "        print('cross dataset is cached in file: cross.data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='7'></a>7. Corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this on if you want to parse corner information\n",
    "parse_corner = False\n",
    "\n",
    "if parse_corner:\n",
    "    #Create empty lists to store extracted data\n",
    "    id_list=[]\n",
    "    type_list=[]\n",
    "    subtype_list=[]\n",
    "    player1_list=[]\n",
    "    team_list=[]\n",
    "    elapsed_list=[]\n",
    "    match_id_list=[]\n",
    "    elapsed_plus_list=[]\n",
    "    \n",
    "    # Loop over all available rows\n",
    "    for i in tqdm(np.arange(match[match['corner'].notnull()].shape[0]), desc='Extracting Corner Events', unit='matches'):\n",
    "        \n",
    "        # Create a soup to parse\n",
    "        soup = bs4.BeautifulSoup(match[match['corner'].notnull()].iloc[i]['corner'],'lxml')\n",
    "        \n",
    "        # Loop over all events\n",
    "        for element in soup.corner.find_all('value',recursive=False):\n",
    "            \n",
    "            # Get event id\n",
    "            try:\n",
    "                id_list.append(element.find('id').text)\n",
    "            except AttributeError:\n",
    "                id_list.append(np.nan)\n",
    "            \n",
    "            # Get event type\n",
    "            try:\n",
    "                type_list.append(element.find('type').text)\n",
    "            except AttributeError:\n",
    "                type_list.append(np.nan)\n",
    "            \n",
    "            # Get event subtype\n",
    "            try:\n",
    "                subtype_list.append(element.find('subtype').text)\n",
    "            except AttributeError:\n",
    "                subtype_list.append(np.nan)\n",
    "            \n",
    "            # Get player1\n",
    "            try:\n",
    "                player1_list.append(element.find('player1').text)\n",
    "            except AttributeError:\n",
    "                player1_list.append(np.nan)\n",
    "            \n",
    "            # Get team\n",
    "            try:\n",
    "                team_list.append(element.find('team').text)\n",
    "            except AttributeError:\n",
    "                team_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed time\n",
    "            try:\n",
    "                elapsed_list.append(element.find('elapsed').text)\n",
    "            except AttributeError:\n",
    "                elapsed_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed plus_time\n",
    "            try:\n",
    "                elapsed_plus_list.append(element.find('elapsed_plus').text)\n",
    "            except AttributeError:\n",
    "                elapsed_plus_list.append(np.nan)\n",
    "            \n",
    "            # Get match id\n",
    "            match_id_list.append(match[match['corner'].notnull()].iloc[i]['match_api_id'])\n",
    "    \n",
    "    # Create a dictionary\n",
    "    corner_dic = {'id': id_list,                        \n",
    "                  'type': type_list,                        \n",
    "                  'subtype':subtype_list,                        \n",
    "                  'player1': player1_list,             \n",
    "                  'team': team_list,              \n",
    "                  'elapsed': elapsed_list,             \n",
    "                  'elapsed_plus':elapsed_plus_list,             \n",
    "                  'match_api_id':match_id_list}\n",
    "    \n",
    "    # Create a dataframe\n",
    "    corner = pd.DataFrame(corner_dic)\n",
    "    \n",
    "    # Change data types to be consistent with database\n",
    "    corner.elapsed = pd.to_numeric(corner.elapsed, errors='coerce')\n",
    "    corner.elapsed_plus = pd.to_numeric(corner.elapsed_plus, errors='coerce')\n",
    "    corner.id = pd.to_numeric(corner.id, errors='coerce')\n",
    "    corner.player1 = pd.to_numeric(corner.player1, errors='coerce')\n",
    "    corner.team = pd.to_numeric(corner.team, errors='coerce')\n",
    "    \n",
    "    # If data file has not been generated in the same folder yet\n",
    "    if not os.path.isfile(os.path.join(export_folder, 'corner.data')):\n",
    "        print('Saving corner dataset to file...')\n",
    "        try:\n",
    "            with open(os.path.join(export_folder, 'corner.data'), 'wb') as f:\n",
    "                pickle.dump(corner, f)\n",
    "            print('corner dataset has been saved to corner.data')\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to: corner.data')\n",
    "    else:\n",
    "        print('corner dataset is cached in file: corner.data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='8'></a>8. Possession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this on if you want to parse possession information\n",
    "parse_pos = False\n",
    "\n",
    "if parse_pos:\n",
    "    #Create empty lists to store extracted data\n",
    "    id_list=[]\n",
    "    type_list=[]\n",
    "    subtype_list=[]\n",
    "    elapsed_list=[]\n",
    "    match_id_list=[]\n",
    "    awaypos_list=[]\n",
    "    homepos_list=[]\n",
    "    elapsed_plus_list=[]\n",
    "    \n",
    "    # Loop over all available rows\n",
    "    for i in tqdm(np.arange(match[match['possession'].notnull()].shape[0]), desc='Extracting Possession Events', unit='matches'):\n",
    "        \n",
    "        # Create a soup to parse\n",
    "        soup = bs4.BeautifulSoup(match[match['possession'].notnull()].iloc[i]['possession'],'lxml')\n",
    "        \n",
    "        # Loop over all events\n",
    "        for element in soup.possession.find_all('value',recursive=False):\n",
    "            \n",
    "            # Get event id\n",
    "            try:\n",
    "                id_list.append(element.find('id').text)\n",
    "            except AttributeError:\n",
    "                id_list.append(np.nan)\n",
    "            \n",
    "            # Get event type\n",
    "            try:\n",
    "                type_list.append(element.find('type').text)\n",
    "            except AttributeError:\n",
    "                type_list.append(np.nan)\n",
    "            \n",
    "            # Get event subtype\n",
    "            try:\n",
    "                subtype_list.append(element.find('subtype').text)\n",
    "            except AttributeError:\n",
    "                subtype_list.append(np.nan)\n",
    "                        \n",
    "            # Get elapsed time\n",
    "            try:\n",
    "                elapsed_list.append(element.find('elapsed').text)\n",
    "            except AttributeError:\n",
    "                elapsed_list.append(np.nan)\n",
    "            \n",
    "            # Get away team possession\n",
    "            try:\n",
    "                awaypos_list.append(element.find('awaypos').text)\n",
    "            except AttributeError:\n",
    "                awaypos_list.append(np.nan)\n",
    "            \n",
    "            # Get home team possession\n",
    "            try:\n",
    "                homepos_list.append(element.find('homepos').text)\n",
    "            except AttributeError:\n",
    "                homepos_list.append(np.nan)\n",
    "            \n",
    "            # Get elapsed plus_time\n",
    "            try:\n",
    "                elapsed_plus_list.append(element.find('elapsed_plus').text)\n",
    "            except AttributeError:\n",
    "                elapsed_plus_list.append(np.nan)        \n",
    "            \n",
    "            # Get match id\n",
    "            match_id_list.append(match[match['possession'].notnull()].iloc[i]['match_api_id'])\n",
    "    \n",
    "    # Create a dictionary\n",
    "    possession_dic = {'id': id_list,                        \n",
    "                      'type': type_list,                        \n",
    "                      'subtype':subtype_list,                        \n",
    "                      'awaypos': awaypos_list,\n",
    "                      'homepos': homepos_list,                         \n",
    "                      'elapsed': elapsed_list,\n",
    "                      'elapsed_plus':elapsed_plus_list,\n",
    "                      'match_api_id':match_id_list}\n",
    "    \n",
    "    # Create a dataframe\n",
    "    possession = pd.DataFrame(possession_dic)\n",
    "    \n",
    "    # Change data types to be consistent with database\n",
    "    possession.elapsed = pd.to_numeric(possession.elapsed, errors='coerce')\n",
    "    possession.elapsed_plus = pd.to_numeric(possession.elapsed_plus, errors='coerce')\n",
    "    possession.id = pd.to_numeric(possession.id, errors='coerce')\n",
    "    possession.awaypos = pd.to_numeric(possession.awaypos, errors='coerce')\n",
    "    possession.homepos = pd.to_numeric(possession.homepos, errors='coerce')\n",
    "    \n",
    "    # Save to local disk\n",
    "    # If data file has not been generated in the same folder yet\n",
    "    if not os.path.isfile(os.path.join(export_folder, 'possession.data')):\n",
    "        print('Saving corner dataset to file...')\n",
    "        try:\n",
    "            with open(os.path.join(export_folder, 'possession.data'), 'wb') as f:\n",
    "                pickle.dump(possession, f)\n",
    "            print('possession dataset has been saved to possession.data')\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to: possession.data')\n",
    "    else:\n",
    "        print('possession dataset is cached in file: possession.data.')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
